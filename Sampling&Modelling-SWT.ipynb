{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from collections import OrderedDict\n",
    "except ImportError:\n",
    "    from ordereddict import OrderedDict\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Array\n",
    "import numpy as np\n",
    "\n",
    "# Decompress the file\n",
    "import gzip\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "# Datetime\n",
    "from datetime import datetime\n",
    "\n",
    "## Warnings\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Large dataset\n",
    "import dask.bag as db\n",
    "Cleanreview_df = pd.read_csv('Cleanreview_VideoGames.csv' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>ReviewerID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ReviewerName</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>Price</th>\n",
       "      <th>Categories</th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>RatingClass</th>\n",
       "      <th>ReviewDate</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>A1HP7NVNPFMA4N</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Ambrosia075</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>but when you do it's great. This game is a bit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>great game bite hard get hang great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>A1JGAP0185YJI6</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>travis</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>But in spite of that it was fun, I liked it I ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>spite fun like play alright steam bite trouble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1YJWEXHQBWK2B</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Vincent G. Mezera</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>Three Stars ok game.</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>three star ok game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>A2204E1TH211HT</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Grandma KR</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>Two Stars found the game a bit too complicated...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>two star find game bite complicate not expect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A2RF5B5H74JLPE</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>jon</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>love this game great game, I love it and have ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>love game great game love play since arrive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      ReviewerID   ProductID       ReviewerName  \\\n",
       "0       5  A1HP7NVNPFMA4N  0700026657        Ambrosia075   \n",
       "1       4  A1JGAP0185YJI6  0700026657             travis   \n",
       "2       3  A1YJWEXHQBWK2B  0700026657  Vincent G. Mezera   \n",
       "3       2  A2204E1TH211HT  0700026657         Grandma KR   \n",
       "4       5  A2RF5B5H74JLPE  0700026657                jon   \n",
       "\n",
       "                                  ProductDescription  Price  \\\n",
       "0  Anno 2070, the newest version of the award-win...  39.99   \n",
       "1  Anno 2070, the newest version of the award-win...  39.99   \n",
       "2  Anno 2070, the newest version of the award-win...  39.99   \n",
       "3  Anno 2070, the newest version of the award-win...  39.99   \n",
       "4  Anno 2070, the newest version of the award-win...  39.99   \n",
       "\n",
       "                         Categories  \\\n",
       "0  [['Video Games', 'PC', 'Games']]   \n",
       "1  [['Video Games', 'PC', 'Games']]   \n",
       "2  [['Video Games', 'PC', 'Games']]   \n",
       "3  [['Video Games', 'PC', 'Games']]   \n",
       "4  [['Video Games', 'PC', 'Games']]   \n",
       "\n",
       "                                          ReviewText RatingClass  ReviewDate  \\\n",
       "0  but when you do it's great. This game is a bit...    positive  2015-10-17   \n",
       "1  But in spite of that it was fun, I liked it I ...    positive  2015-07-27   \n",
       "2                               Three Stars ok game.    positive  2015-02-23   \n",
       "3  Two Stars found the game a bit too complicated...    negative  2015-02-20   \n",
       "4  love this game great game, I love it and have ...    positive  2014-12-25   \n",
       "\n",
       "                                           CleanText  \n",
       "0                great game bite hard get hang great  \n",
       "1  spite fun like play alright steam bite trouble...  \n",
       "2                                 three star ok game  \n",
       "3  two star find game bite complicate not expect ...  \n",
       "4        love game great game love play since arrive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleanreview_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 497240 entries, 0 to 497239\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Rating              497240 non-null  int64  \n",
      " 1   ReviewerID          497240 non-null  object \n",
      " 2   ProductID           497240 non-null  object \n",
      " 3   ReviewerName        497131 non-null  object \n",
      " 4   ProductDescription  287372 non-null  object \n",
      " 5   Price               356582 non-null  float64\n",
      " 6   Categories          359654 non-null  object \n",
      " 7   ReviewText          497240 non-null  object \n",
      " 8   RatingClass         497240 non-null  object \n",
      " 9   ReviewDate          497240 non-null  object \n",
      " 10  CleanText           497187 non-null  object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 41.7+ MB\n"
     ]
    }
   ],
   "source": [
    "Cleanreview_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>ReviewerID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ReviewerName</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>Price</th>\n",
       "      <th>Categories</th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>RatingClass</th>\n",
       "      <th>ReviewDate</th>\n",
       "      <th>CleanText</th>\n",
       "      <th>ReviewYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>A1HP7NVNPFMA4N</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Ambrosia075</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>but when you do it's great. This game is a bit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>great game bite hard get hang great</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>A1JGAP0185YJI6</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>travis</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>But in spite of that it was fun, I liked it I ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>spite fun like play alright steam bite trouble...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1YJWEXHQBWK2B</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Vincent G. Mezera</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>Three Stars ok game.</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>three star ok game</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>A2204E1TH211HT</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Grandma KR</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>Two Stars found the game a bit too complicated...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>two star find game bite complicate not expect ...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A2RF5B5H74JLPE</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>jon</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>love this game great game, I love it and have ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>love game great game love play since arrive</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      ReviewerID   ProductID       ReviewerName  \\\n",
       "0       5  A1HP7NVNPFMA4N  0700026657        Ambrosia075   \n",
       "1       4  A1JGAP0185YJI6  0700026657             travis   \n",
       "2       3  A1YJWEXHQBWK2B  0700026657  Vincent G. Mezera   \n",
       "3       2  A2204E1TH211HT  0700026657         Grandma KR   \n",
       "4       5  A2RF5B5H74JLPE  0700026657                jon   \n",
       "\n",
       "                                  ProductDescription  Price  \\\n",
       "0  Anno 2070, the newest version of the award-win...  39.99   \n",
       "1  Anno 2070, the newest version of the award-win...  39.99   \n",
       "2  Anno 2070, the newest version of the award-win...  39.99   \n",
       "3  Anno 2070, the newest version of the award-win...  39.99   \n",
       "4  Anno 2070, the newest version of the award-win...  39.99   \n",
       "\n",
       "                         Categories  \\\n",
       "0  [['Video Games', 'PC', 'Games']]   \n",
       "1  [['Video Games', 'PC', 'Games']]   \n",
       "2  [['Video Games', 'PC', 'Games']]   \n",
       "3  [['Video Games', 'PC', 'Games']]   \n",
       "4  [['Video Games', 'PC', 'Games']]   \n",
       "\n",
       "                                          ReviewText RatingClass ReviewDate  \\\n",
       "0  but when you do it's great. This game is a bit...    positive 2015-10-17   \n",
       "1  But in spite of that it was fun, I liked it I ...    positive 2015-07-27   \n",
       "2                               Three Stars ok game.    positive 2015-02-23   \n",
       "3  Two Stars found the game a bit too complicated...    negative 2015-02-20   \n",
       "4  love this game great game, I love it and have ...    positive 2014-12-25   \n",
       "\n",
       "                                           CleanText  ReviewYear  \n",
       "0                great game bite hard get hang great        2015  \n",
       "1  spite fun like play alright steam bite trouble...        2015  \n",
       "2                                 three star ok game        2015  \n",
       "3  two star find game bite complicate not expect ...        2015  \n",
       "4        love game great game love play since arrive        2014  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['date'].dt.year\n",
    "Cleanreview_df['ReviewDate'] = pd.to_datetime(Cleanreview_df['ReviewDate'])\n",
    "\n",
    "Cleanreview_df['ReviewYear'] = Cleanreview_df['ReviewDate'].dt.year\n",
    "Cleanreview_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (from imblearn) (0.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.7/site-packages (0.24.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from catboost) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from catboost) (1.19.5)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from catboost) (0.16)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from catboost) (4.14.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from catboost) (3.2.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (4.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.3.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 497240 entries, 0 to 497239\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   Rating              497240 non-null  int64         \n",
      " 1   ReviewerID          497240 non-null  object        \n",
      " 2   ProductID           497240 non-null  object        \n",
      " 3   ReviewerName        497131 non-null  object        \n",
      " 4   ProductDescription  287372 non-null  object        \n",
      " 5   Price               356582 non-null  float64       \n",
      " 6   Categories          359654 non-null  object        \n",
      " 7   ReviewText          497240 non-null  object        \n",
      " 8   RatingClass         497240 non-null  object        \n",
      " 9   ReviewDate          497240 non-null  datetime64[ns]\n",
      " 10  CleanText           497187 non-null  object        \n",
      " 11  ReviewYear          497240 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(8)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "Cleanreview_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleanreview_df.isnull().sum()\n",
    "\n",
    "Cleanreview_df=Cleanreview_df.dropna(subset=['CleanText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating                     0\n",
       "ReviewerID                 0\n",
       "ProductID                  0\n",
       "ReviewerName             109\n",
       "ProductDescription    209843\n",
       "Price                 140639\n",
       "Categories            137567\n",
       "ReviewText                 0\n",
       "RatingClass                0\n",
       "ReviewDate                 0\n",
       "CleanText                  0\n",
       "ReviewYear                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleanreview_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497187 entries, 0 to 497239\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   Rating              497187 non-null  int64         \n",
      " 1   ReviewerID          497187 non-null  object        \n",
      " 2   ProductID           497187 non-null  object        \n",
      " 3   ReviewerName        497078 non-null  object        \n",
      " 4   ProductDescription  287344 non-null  object        \n",
      " 5   Price               356548 non-null  float64       \n",
      " 6   Categories          359620 non-null  object        \n",
      " 7   ReviewText          497187 non-null  object        \n",
      " 8   RatingClass         497187 non-null  object        \n",
      " 9   ReviewDate          497187 non-null  datetime64[ns]\n",
      " 10  CleanText           497187 non-null  object        \n",
      " 11  ReviewYear          497187 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(8)\n",
      "memory usage: 49.3+ MB\n"
     ]
    }
   ],
   "source": [
    "Cleanreview_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>ReviewerID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ReviewerName</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>Price</th>\n",
       "      <th>Categories</th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>RatingClass</th>\n",
       "      <th>ReviewDate</th>\n",
       "      <th>CleanText</th>\n",
       "      <th>ReviewYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497239</th>\n",
       "      <td>2</td>\n",
       "      <td>A6W81WTFK940B</td>\n",
       "      <td>B01HIZGKOE</td>\n",
       "      <td>msam420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not as good as I expected it to be The graphic...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>not good expect graphics terrible look like ps...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497238</th>\n",
       "      <td>4</td>\n",
       "      <td>A34GG58TJ1A3SH</td>\n",
       "      <td>B01HIZF7XE</td>\n",
       "      <td>seamonkey10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It's Okay, Nothing Profound I think I original...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-08-05</td>\n",
       "      <td>okay nothing profound think originally begin p...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497237</th>\n",
       "      <td>3</td>\n",
       "      <td>ACIZ77IGIX2JL</td>\n",
       "      <td>B01HH6JEOC</td>\n",
       "      <td>Era</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Only buy on sale. This does add some kids room...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>buy sale add kid room things nice right not se...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497236</th>\n",
       "      <td>3</td>\n",
       "      <td>A1RS06313BL6WN</td>\n",
       "      <td>B01HH6JEOC</td>\n",
       "      <td>Tom Stopsign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three Stars Okay stuff.</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>three star okay stuff</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497235</th>\n",
       "      <td>4</td>\n",
       "      <td>AVECM71LSZLC5</td>\n",
       "      <td>B01HGPUTCA</td>\n",
       "      <td>boris teplitskiy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Four Stars not OEM but good replacement parts</td>\n",
       "      <td>positive</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>four star not oehem good replacehement part</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A2RF5B5H74JLPE</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>jon</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>love this game great game, I love it and have ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>love game great game love play since arrive</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>A2204E1TH211HT</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Grandma KR</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>Two Stars found the game a bit too complicated...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2015-02-20</td>\n",
       "      <td>two star find game bite complicate not expect ...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1YJWEXHQBWK2B</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Vincent G. Mezera</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>Three Stars ok game.</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>three star ok game</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>A1JGAP0185YJI6</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>travis</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>But in spite of that it was fun, I liked it I ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>spite fun like play alright steam bite trouble...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>A1HP7NVNPFMA4N</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Ambrosia075</td>\n",
       "      <td>Anno 2070, the newest version of the award-win...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>[['Video Games', 'PC', 'Games']]</td>\n",
       "      <td>but when you do it's great. This game is a bit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>great game bite hard get hang great</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497187 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rating      ReviewerID   ProductID       ReviewerName  \\\n",
       "497239       2   A6W81WTFK940B  B01HIZGKOE            msam420   \n",
       "497238       4  A34GG58TJ1A3SH  B01HIZF7XE        seamonkey10   \n",
       "497237       3   ACIZ77IGIX2JL  B01HH6JEOC                Era   \n",
       "497236       3  A1RS06313BL6WN  B01HH6JEOC       Tom Stopsign   \n",
       "497235       4   AVECM71LSZLC5  B01HGPUTCA   boris teplitskiy   \n",
       "...        ...             ...         ...                ...   \n",
       "4            5  A2RF5B5H74JLPE  0700026657                jon   \n",
       "3            2  A2204E1TH211HT  0700026657         Grandma KR   \n",
       "2            3  A1YJWEXHQBWK2B  0700026657  Vincent G. Mezera   \n",
       "1            4  A1JGAP0185YJI6  0700026657             travis   \n",
       "0            5  A1HP7NVNPFMA4N  0700026657        Ambrosia075   \n",
       "\n",
       "                                       ProductDescription  Price  \\\n",
       "497239                                                NaN    NaN   \n",
       "497238                                                NaN    NaN   \n",
       "497237                                                NaN    NaN   \n",
       "497236                                                NaN    NaN   \n",
       "497235                                                NaN    NaN   \n",
       "...                                                   ...    ...   \n",
       "4       Anno 2070, the newest version of the award-win...  39.99   \n",
       "3       Anno 2070, the newest version of the award-win...  39.99   \n",
       "2       Anno 2070, the newest version of the award-win...  39.99   \n",
       "1       Anno 2070, the newest version of the award-win...  39.99   \n",
       "0       Anno 2070, the newest version of the award-win...  39.99   \n",
       "\n",
       "                              Categories  \\\n",
       "497239                               NaN   \n",
       "497238                               NaN   \n",
       "497237                               NaN   \n",
       "497236                               NaN   \n",
       "497235                               NaN   \n",
       "...                                  ...   \n",
       "4       [['Video Games', 'PC', 'Games']]   \n",
       "3       [['Video Games', 'PC', 'Games']]   \n",
       "2       [['Video Games', 'PC', 'Games']]   \n",
       "1       [['Video Games', 'PC', 'Games']]   \n",
       "0       [['Video Games', 'PC', 'Games']]   \n",
       "\n",
       "                                               ReviewText RatingClass  \\\n",
       "497239  Not as good as I expected it to be The graphic...    negative   \n",
       "497238  It's Okay, Nothing Profound I think I original...    positive   \n",
       "497237  Only buy on sale. This does add some kids room...    positive   \n",
       "497236                            Three Stars Okay stuff.    positive   \n",
       "497235      Four Stars not OEM but good replacement parts    positive   \n",
       "...                                                   ...         ...   \n",
       "4       love this game great game, I love it and have ...    positive   \n",
       "3       Two Stars found the game a bit too complicated...    negative   \n",
       "2                                    Three Stars ok game.    positive   \n",
       "1       But in spite of that it was fun, I liked it I ...    positive   \n",
       "0       but when you do it's great. This game is a bit...    positive   \n",
       "\n",
       "       ReviewDate                                          CleanText  \\\n",
       "497239 2018-03-13  not good expect graphics terrible look like ps...   \n",
       "497238 2018-08-05  okay nothing profound think originally begin p...   \n",
       "497237 2017-08-07  buy sale add kid room things nice right not se...   \n",
       "497236 2018-08-20                              three star okay stuff   \n",
       "497235 2017-07-01        four star not oehem good replacehement part   \n",
       "...           ...                                                ...   \n",
       "4      2014-12-25        love game great game love play since arrive   \n",
       "3      2015-02-20  two star find game bite complicate not expect ...   \n",
       "2      2015-02-23                                 three star ok game   \n",
       "1      2015-07-27  spite fun like play alright steam bite trouble...   \n",
       "0      2015-10-17                great game bite hard get hang great   \n",
       "\n",
       "        ReviewYear  \n",
       "497239        2018  \n",
       "497238        2018  \n",
       "497237        2017  \n",
       "497236        2018  \n",
       "497235        2017  \n",
       "...            ...  \n",
       "4             2014  \n",
       "3             2015  \n",
       "2             2015  \n",
       "1             2015  \n",
       "0             2015  \n",
       "\n",
       "[497187 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleanreview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sliding window sampling\n",
    "\n",
    "Cleanreview_df = Cleanreview_df.iloc[::-1]\n",
    "    # The frame can be made into a time series, a numeric index is preserved\n",
    "'''\n",
    "    dataframe['Date'] = pd.to_datetime(dataframe.Date)\n",
    "    dataframe['Year'] = dataframe.Date.dt.year\n",
    "    dataframe['Month'] = dataframe.Date.dt.month\n",
    "'''\n",
    "Cleanreview_df[\"Num_Index\"] = range(1, 497188)\n",
    "Cleanreview_df = Cleanreview_df.set_index('ReviewDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# define the dataset location\n",
    "\n",
    "X = Cleanreview_df['CleanText']\n",
    "y = Cleanreview_df['Rating']\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497187,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yellowbrick in /opt/conda/lib/python3.7/site-packages (1.3.post1)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.7/site-packages (from yellowbrick) (0.24.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from yellowbrick) (3.2.1)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from yellowbrick) (0.10.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from yellowbrick) (1.4.1)\n",
      "Requirement already satisfied: numpy<1.20,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from yellowbrick) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20->yellowbrick) (0.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20->yellowbrick) (2.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10.0->yellowbrick) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError\n",
    "from yellowbrick.model_selection import FeatureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(max_train_size=80000, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=10,test_size=20000, max_train_size=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None)\n"
     ]
    }
   ],
   "source": [
    "print(tscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "prev_train = 0\n",
    "trained_on = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "\n",
    "#   An array of indices are created that starts\n",
    "#   at the finish of the previous training set\n",
    "#   & ends on the start of the current test set\n",
    "\n",
    "    last_step = test_index[0]\n",
    "    a_train_index = np.arange(prev_train, last_step)\n",
    "\n",
    "#   Train & Test portions are then allocated   \n",
    "   # X_train, X_test = X.iloc[a_train_index], X.iloc[test_index]\n",
    "   # y_train, y_test = y.iloc[a_train_index], y.iloc[test_index]\n",
    "    X_train, X_test = X[a_train_index], X[test_index]\n",
    "    y_train, y_test = y[a_train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451989, 308634)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451989,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (4.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451989, 308634)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451989,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45198, 308634)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function call for Logistic Regression\n",
    "\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "predictions = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.58      0.56      2065\n",
      "           2       0.41      0.20      0.27      2227\n",
      "           3       0.45      0.34      0.39      4644\n",
      "           4       0.50      0.35      0.41      9720\n",
      "           5       0.76      0.91      0.83     26542\n",
      "\n",
      "    accuracy                           0.68     45198\n",
      "   macro avg       0.53      0.48      0.49     45198\n",
      "weighted avg       0.65      0.68      0.65     45198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modelling using Naive Bayes\n",
    "# instantiate learning model alpha = optimal_alpha\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_optimal =  MultinomialNB(alpha = 1.0)\n",
    "\n",
    "# fitting the model\n",
    "nb_optimal.fit(X_train, y_train)\n",
    "\n",
    "# predict the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb_optimal.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.01      0.01      2065\n",
      "           2       0.00      0.00      0.00      2227\n",
      "           3       0.69      0.00      0.01      4644\n",
      "           4       0.44      0.04      0.07      9720\n",
      "           5       0.59      0.99      0.74     26542\n",
      "\n",
      "    accuracy                           0.59     45198\n",
      "   macro avg       0.50      0.21      0.17     45198\n",
      "weighted avg       0.55      0.59      0.45     45198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.18.4)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras) (1.14.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.11.4)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.4.2)\n",
      "Processing ./.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6/wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Using cached grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Processing ./.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting wheel~=0.35\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (46.1.3.post20200325)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.3-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.16.1)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.9)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Installing collected packages: flatbuffers, six, absl-py, numpy, opt-einsum, wheel, astunparse, keras-preprocessing, wrapt, markdown, google-auth-oauthlib, tensorboard-plugin-wit, grpcio, werkzeug, tensorboard, gast, termcolor, google-pasta, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.14.0\n",
      "    Uninstalling six-1.14.0:\n",
      "      Successfully uninstalled six-1.14.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.4\n",
      "    Uninstalling numpy-1.18.4:\n",
      "      Successfully uninstalled numpy-1.18.4\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.3.3 google-auth-oauthlib-0.4.3 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 opt-einsum-3.3.0 six-1.15.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266/nltk-3.5-py3-none-any.whl\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (0.15.1)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.3.17-cp37-cp37m-manylinux2014_x86_64.whl (721 kB)\n",
      "\u001b[K     |████████████████████████████████| 721 kB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.45.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.5 regex-2021.3.17\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly==4.14.3 in /opt/conda/lib/python3.7/site-packages (4.14.3)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly==4.14.3) (1.3.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from plotly==4.14.3) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly==4.14.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chart_studio\n",
      "  Using cached chart_studio-1.1.0-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from chart_studio) (1.3.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from chart_studio) (1.15.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from chart_studio) (2.23.0)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from chart_studio) (4.14.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->chart_studio) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->chart_studio) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->chart_studio) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->chart_studio) (1.25.9)\n",
      "Installing collected packages: chart-studio\n",
      "Successfully installed chart-studio-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chart_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./.cache/pip/wheels/e1/27/13/3fe67fa7ea7be444b831d117220b3b586b872c9acd4df480d0/cufflinks-0.17.3-py3-none-any.whl\n",
      "Requirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from cufflinks) (7.14.0)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in /opt/conda/lib/python3.7/site-packages (from cufflinks) (46.1.3.post20200325)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from cufflinks) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /opt/conda/lib/python3.7/site-packages (from cufflinks) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /opt/conda/lib/python3.7/site-packages (from cufflinks) (1.0.3)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/lib/python3.7/site-packages (from cufflinks) (7.5.1)\n",
      "Collecting colorlover>=0.2.1\n",
      "  Using cached colorlover-0.3.0-py3-none-any.whl (8.9 kB)\n",
      "Requirement already satisfied: plotly>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from cufflinks) (4.14.3)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (2.6.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (0.17.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (3.0.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (4.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.3.0->cufflinks) (4.3.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.19.2->cufflinks) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.19.2->cufflinks) (2.8.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->cufflinks) (5.3.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->cufflinks) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->cufflinks) (5.0.6)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly>=4.1.1->cufflinks) (1.3.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.3.0->cufflinks) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.3.0->cufflinks) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->cufflinks) (0.1.9)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2->ipython>=5.3.0->cufflinks) (0.2.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (6.0.4)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (6.1.3)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (6.0.3)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (4.6.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (3.2.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (19.0.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (5.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (2.11.2)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (1.6.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (0.16.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.3)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.4)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (3.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (3.1.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (2.4.7)\n",
      "Installing collected packages: colorlover, cufflinks\n",
      "Successfully installed colorlover-0.3.0 cufflinks-0.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cufflinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LSTM modelling\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objs as go\n",
    "#import plotly.plotly as py\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX = Cleanreview_df['CleanText']\\ny = Cleanreview_df['Rating']\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 308309 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "\n",
    "'''\n",
    "X = Cleanreview_df['CleanText']\n",
    "y = Cleanreview_df['Rating']\n",
    "'''\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each Review.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "#, lower=True\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True\n",
    "                     )\n",
    "tokenizer.fit_on_texts(Cleanreview_df['CleanText'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (497187, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(Cleanreview_df['CleanText'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (497187, 5)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(Cleanreview_df['Rating']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.utils.validation import _num_samples\n",
    "\n",
    "class TimeSeriesSplitCustom(TimeSeriesSplit):\n",
    "    def __init__(self, n_splits=5, max_train_size=None,\n",
    "                 test_size=1,\n",
    "                 min_train_size=1):\n",
    "        super().__init__(n_splits=n_splits, max_train_size=max_train_size)\n",
    "        self.test_size = test_size\n",
    "        self.min_train_size = min_train_size\n",
    "\n",
    "    def overlapping_split(self, X, y=None, groups=None):\n",
    "        min_train_size = self.min_train_size\n",
    "        test_size = self.test_size\n",
    "\n",
    "        n_splits = self.n_splits\n",
    "        n_samples = _num_samples(X)\n",
    "\n",
    "        if (n_samples - min_train_size) / test_size >= n_splits:\n",
    "            print('(n_samples -  min_train_size) / test_size >= n_splits')\n",
    "            print('default TimeSeriesSplit.split() used')\n",
    "            yield from super().split(X)\n",
    "\n",
    "        else:\n",
    "            shift = int(np.floor(\n",
    "                (n_samples - test_size - min_train_size) / (n_splits - 1)))\n",
    "\n",
    "            start_test = n_samples - (n_splits * shift + test_size - shift)\n",
    "\n",
    "            test_starts = range(start_test, n_samples - test_size + 1, shift)\n",
    "\n",
    "            if start_test < min_train_size:\n",
    "                raise ValueError(\n",
    "                    (\"The start of the testing : {0} is smaller\"\n",
    "                     \" than the minimum training samples: {1}.\").format(start_test,\n",
    "                                                                        min_train_size))\n",
    "\n",
    "            indices = np.arange(n_samples)\n",
    "\n",
    "            for test_start in test_starts:\n",
    "                if self.max_train_size and self.max_train_size < test_start:\n",
    "                    yield (indices[test_start - self.max_train_size:test_start],\n",
    "                           indices[test_start:test_start + test_size])\n",
    "                else:\n",
    "                    yield (indices[:test_start],\n",
    "                           indices[test_start:test_start + test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv=TimeSeriesSplitCustom(n_splits=10, test_size=20000, min_train_size=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_train = 0\n",
    "trained_on = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "\n",
    "#   An array of indices are created that starts\n",
    "#   at the finish of the previous training set\n",
    "#   & ends on the start of the current test set\n",
    "\n",
    "    last_step = test_index[0]\n",
    "    a_train_index = np.arange(prev_train, last_step)\n",
    "\n",
    "#   Train & Test portions are then allocated   \n",
    "   # X_train, X_test = X.iloc[a_train_index], X.iloc[test_index]\n",
    "   # y_train, y_test = y.iloc[a_train_index], y.iloc[test_index]\n",
    "    X_train, X_test = X[a_train_index], X[test_index]\n",
    "    y_train, y_test = Y[a_train_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477187, 250) (477187, 5)\n",
      "(20000, 250) (20000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_train, y_train,train_size=90000,\n",
    "                                                  test_size = 30000,\n",
    "                                                  random_state=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 250) (90000, 5)\n",
      "(30000, 250) (30000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 5,080,905\n",
      "Trainable params: 5,080,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1266/1266 [==============================] - 752s 591ms/step - loss: 0.9128 - accuracy: 0.6484 - val_loss: 0.7144 - val_accuracy: 0.7130\n",
      "Epoch 2/5\n",
      "1266/1266 [==============================] - 739s 584ms/step - loss: 0.6408 - accuracy: 0.7419 - val_loss: 0.6844 - val_accuracy: 0.7248\n",
      "Epoch 3/5\n",
      "1266/1266 [==============================] - 733s 579ms/step - loss: 0.5564 - accuracy: 0.7829 - val_loss: 0.6819 - val_accuracy: 0.7234\n",
      "Epoch 4/5\n",
      "1266/1266 [==============================] - 731s 577ms/step - loss: 0.4892 - accuracy: 0.8125 - val_loss: 0.7112 - val_accuracy: 0.7153\n",
      "Epoch 5/5\n",
      "1266/1266 [==============================] - 740s 584ms/step - loss: 0.4267 - accuracy: 0.8382 - val_loss: 0.7726 - val_accuracy: 0.7144\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,) (20000, 5)\n",
      "[3 4 4 4 3] [[1.48051313e-05 7.55738120e-06 1.80945048e-04 9.97719586e-01\n",
      "  2.07707332e-03]\n",
      " [2.84047492e-05 5.74448995e-06 1.05943036e-04 3.43446329e-04\n",
      "  9.99516487e-01]\n",
      " [1.61807242e-04 4.79152959e-06 7.49792307e-05 9.00321538e-05\n",
      "  9.99668360e-01]\n",
      " [4.39545140e-03 8.43503326e-03 4.39227298e-02 1.48705587e-01\n",
      "  7.94541121e-01]\n",
      " [1.43229379e-04 5.61881345e-04 2.70361025e-02 7.20617652e-01\n",
      "  2.51641035e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# predict \n",
    "pred = model.predict(X_test, batch_size = 32)\n",
    "#pred = np.argmax(predictions, axis=1)\n",
    "# label\n",
    "y_train = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(y_train.shape, pred.shape)\n",
    "print(y_train[:5], pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.51      0.51       822\n",
      "           1       0.31      0.24      0.27       822\n",
      "           2       0.38      0.38      0.38      1762\n",
      "           3       0.43      0.42      0.43      3792\n",
      "           4       0.83      0.85      0.84     12802\n",
      "\n",
      "    accuracy                           0.69     20000\n",
      "   macro avg       0.49      0.48      0.49     20000\n",
      "weighted avg       0.68      0.69      0.69     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, np.argmax(pred, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,) (30000, 5)\n",
      "[3 3 0 4 3] [[9.5525039e-03 5.6797128e-02 4.2761543e-01 3.7993366e-01 1.2610130e-01]\n",
      " [3.0915282e-04 3.0044079e-04 4.4510472e-03 3.4614924e-01 6.4879006e-01]\n",
      " [9.3707633e-01 1.3723333e-03 1.7779259e-03 1.2419300e-02 4.7354162e-02]\n",
      " [9.3280029e-04 6.8879209e-04 4.7580800e-03 2.3685062e-01 7.5676978e-01]\n",
      " [2.4035696e-03 1.2138725e-02 4.2486575e-02 7.6753688e-01 1.7543422e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# predict \n",
    "pred = model.predict(x_val, batch_size = 32)\n",
    "#pred = np.argmax(predictions, axis=1)\n",
    "# label\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "print(y_val.shape, pred.shape)\n",
    "print(y_val[:5], pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.61      1812\n",
      "           1       0.41      0.33      0.37      1520\n",
      "           2       0.48      0.46      0.47      3031\n",
      "           3       0.52      0.48      0.50      5586\n",
      "           4       0.84      0.88      0.86     18051\n",
      "\n",
      "    accuracy                           0.72     30000\n",
      "   macro avg       0.57      0.55      0.56     30000\n",
      "weighted avg       0.71      0.72      0.71     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, np.argmax(pred, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
